#+TITLE: Projet de mémoire
#+SUBTITLE: Détection des replays dans les vidéos de sport
#+AUTHOR: Billal Boudjoghra
#+LaTeX_CLASS_OPTIONS: [presentation]
#+BEAMER_THEME: Madrid
#+PROPERTY:  header-args :eval no
#+OPTIONS:   H:2 num:t toc:t \n:nil  @:t ::t |:t ^:t -:t f:t *:t <:t
#+BEAMER_HEADER: \setbeamertemplate{footline}[frame number author] \setbeamertemplate{caption}[numbered] \beamertemplatenavigationsymbolsempty \frametitle{} \useoutertheme{miniframes}
#+EXPORT_EXCLUDE_TAGS: noexport

* Introduction
** Sportagraph : Présentation
- son produit : Digital Asset Manager
- mon poste : développeur Scala
- ma tâche : détections des replays dans les vidéos de sport

** Sujet de recherche : Détection des replays dans les vidéos de sport
- en lien avec mon travail en entreprise
- thème vaste : deep learning / computer vision

** Détections des replays
- Les replays sont les moments forts de la vidéo
- Hypothèse : les replays sont compris entre deux logos
- Objectif : détection/reconnaissance des logos
#+CAPTION: Un logo
#+ATTR_LATEX: :width 5cm
[[file:logo_ex.png]]

* Détection par analyse d'image
** ORB (1/3)
- outil : OpenCV
*** Idée
- obtenir des features pour chaque frame de la vidéo (SIFT, ORB)
- appliquer des algorithmes de machine learning sur ces features (K-NN)

** ORB (2/2)
[[file:akaze_window_res2.jpg]]

** ORB : Résultats (3/3)

#+ATTR_LATEX: :width 12cm
file:res_orb.png

** Détection de contours (1/3)
- outil : OpenCV
*** Idée
- détecter les contours pour chaque frame de la vidéo (canny edge detection)
- logo image fixe => les contours des frames logo sont les mêmes 

** Détection de contours (2/3)
[[file:comparison_idea.png]]

** Détection de contours : Résultats (3/3)
[[file:res_match_contour.png]]

* Réseau à convolution
** CNN
- efficace pour la reconnaisance d'image
- utilise la convolution au lieu de la multiplication matricielle
- deux caractéristiques importantes : l'intéraction parcimonieuse et le partage de paramètres

** CNN : opération de convolution
#+CAPTION: Opération de convolution label:convolution
#+ATTR_LATEX: :width 4.5cm
[[file:convolution.png]]
- entrée : une matrice
- applique le kernel sur l'entrée
- sortie : une carte des caractéristiques (feature map)

** CNN : intéraction parcimonieuse
#+CAPTION: Intéraction parcimonieuse (en haut), intéraction non parcimonieuse (en bas) label:sparse-vs-dense
#+ATTR_LATEX: :width 4cm
[[file:sparse_vs_dense.png]]
- taille kernel < taille entrée
- le kernel ne parcourt qu'une petite partie de l'entrée à la fois
- moins de calculs à effectuer

** CNN : partage de paramètres
- un seul kernel itére sur l'entrée de la couche
- le réseau n'apprend que les poids du kernel
- taille kernel << taille entrée

=> beaucoup moins de paramètres à apprendre

** CNN : pooling
#+CAPTION: Pooling & invariance label:pooling
#+ATTR_LATEX: :width 3cm 
[[file:pooling.png]]

- modifie la sortie de la couche de convolution
- fait une approximation de la sortie
- rend la représentation *invariante* à de petits changements sur l'entrée
- améliore la capacité de généralisation des CNN

* Détection par apprentissage profond
** Two-Stream Convolutional Networks (1/4)
Séparation de la tâche de reconnaissance dans les vidéos en 2 parties :
- composante spatialle
- composante temporelle
Un CNN est associé à chaque composante

** Two-Stream Convolutional Networks : Composante spatialle (2/4)
- Classifieur d'image classique (imageNet, GoogLeNet)
- Donne un indice fort sur l'action
- Bénéficie des avancées dans le domaine de l'image

** Two-Stream Convolutional Networks : Composante temporelle (3/4)
#+CAPTION: Flux optique label:optical-flow label:opt-flow
#+ATTR_LATEX: :width 12cm
[[file:optical_flow_slide.jpg]]
- utilise l'algorithme de flux optique
  - détecte le mouvement entre les images de la vidéo
- entrée du CNN temporel : image flux optique

** Two-Stream Convolutional Networks : (4/4)
#+CAPTION: Résultats obtenus par l'approche Two-stream model label:two-stream-res
#+ATTR_LATEX: :width 10cm
[[file:two_stream_res.png]]

Apport de la composante temporelle : +15%

** Réseau à convolution 3D (1)
- article Learning Spatiotemporal Features with 3D Convolutional Networks cite:Tran_2015
- idée :
  - 2D : image
  - 3D : video = image + temps
- apprendre la temporalité grâce à la convolution 3D

** Réseau à convolution 3D (2)
#+CAPTION: Convolution 2D sur une séquence d'image (gauche), convolution 3D sur une séquence d'image (droite) label:c3d-idea
[[file:c3d_idea.png]]
- convolution 2D : produit une image (2D) => perte de l'info temporelle
- convolution 3D : produit une réprésentation 3D => garde l'info temporelle

** Réseau à convolution 3D (3)


* Suite de la recherche
** Objectif
- implémenter l'approche par convolution 3D
- comparer avec l'approche par détection de contours

** Référence
** Table des figures
ref:arch-lstm Ng, J. Y., Hausknecht, M., Vijayanarasimhan, S., Vinyals, O., Monga, R., & Toderici, G., Beyond short snippets: deep networks for video classification, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (),  (2015).  http://dx.doi.org/10.1109/cvpr.2015.7299101. Figure 3

ref:convolution Goodfellow, I., Bengio, Y., & Courville, A., Deep Learning (2016), : MIT Press. Chapitre 9. Figure 9.1

ref:pooling Goodfellow, I., Bengio, Y., & Courville, A., Deep Learning (2016), : MIT Press. Chapitre 9. Figure 9.9

ref:opt-flow Simonyan, K., & Zisserman, A., Two-stream convolutional networks for action recognition in videos, CoRR, abs/1406.2199(),  (2014). Figure 2

ref:two-stream-res Simonyan, K., & Zisserman, A., Two-stream convolutional networks for action recognition in videos, CoRR, abs/1406.2199(),  (2014). Table 4

ref:c3d-idea Tran, D., Bourdev, L., Fergus, R., Torresani, L., & Paluri, M., Learning spatiotemporal features with 3d convolutional networks, 2015 IEEE International Conference on Computer Vision (ICCV), (),  (2015).  http://dx.doi.org/10.1109/iccv.2015.510. Figure 1

** Articles (1/4)
+ Weiss, Y., Torralba, A., & Fergus, R., Spectral Hashing, In D. Koller, D. Schuurmans, Y. Bengio, & L. Bottou (Eds.), Advances in Neural Information Processing Systems 21 (pp. 1753–1760) (2009). : Curran Associates, Inc.
+ Rublee, E., Rabaud, V., Konolige, K., & Bradski, G., Orb: an efficient alternative to sift or surf, 2011 International Conference on Computer Vision, (),  (2011).  http://dx.doi.org/10.1109/iccv.2011.6126544
+ Abd-Almageed, W., Online, simultaneous shot boundary detection and key frame extraction for sports videos using rank tracing, 2008 15th IEEE International Conference on Image Processing, (),  (2008).  http://dx.doi.org/10.1109/icip.2008.4712476
+ Raventós, A., Quijada, R., Torres, L., & Tarrés, F., Automatic summarization of soccer highlights using audio-visual descriptors, SpringerPlus, 4(1),  (2015).  http://dx.doi.org/10.1186/s40064-015-1065-9

** Articles (2/4)
+ Duan, L., Xu, M., Tian, Q., & Xu, C., Mean shift based video segment representation and applications to replay detection, 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing, (),  (2004).  http://dx.doi.org/10.1109/icassp.2004.1327209
+ Goodfellow, I., Bengio, Y., & Courville, A., Deep Learning (2016), : MIT Press.
+ Tran, D., Bourdev, L., Fergus, R., Torresani, L., & Paluri, M., Learning spatiotemporal features with 3d convolutional networks, 2015 IEEE International Conference on Computer Vision (ICCV), (),  (2015).  http://dx.doi.org/10.1109/iccv.2015.510
+ Simonyan, K., & Zisserman, A., Two-stream convolutional networks for action recognition in videos, CoRR, abs/1406.2199(),  (2014). 

** Articles (3/4)
+ Farabet, C., Couprie, C., Najman, L., & LeCun, Y., Learning hierarchical features for scene labeling, IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8), 1915–1929 (2013).  http://dx.doi.org/10.1109/tpami.2012.231
+ Lecun, Y., Bottou, L., Bengio, Y., & Haffner, P., Gradient-based learning applied to document recognition, Proceedings of the IEEE, 86(11), 2278–2324 (1998).  http://dx.doi.org/10.1109/5.726791
+ Ng, J. Y., Hausknecht, M., Vijayanarasimhan, S., Vinyals, O., Monga, R., & Toderici, G., Beyond short snippets: deep networks for video classification, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (),  (2015).  http://dx.doi.org/10.1109/cvpr.2015.7299101
+ Pan, H., Li, B., & Sezan, , Automatic detection of replay segments in broadcast sports programs by detection of logos in scene transitions, IIEEE International Conference on Acoustics Speech and Signal Processing, (),  (2002).  http://dx.doi.org/10.1109/icassp.2002.1004638
** Articles (4/4)
+ Chu, W., Song, Y., & Jaimes, A., Video co-summarization: video summarization by visual co-occurrence, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (),  (2015).  http://dx.doi.org/10.1109/cvpr.2015.7298981
+ Javed, A., Irtaza, A., Khaliq, Y., Malik, H., & Mahmood, M. T., Replay and key-events detection for sports video summarization using confined elliptical local ternary patterns and extreme learning machine, Applied Intelligence, 49(8), 2899–2917 (2019).  http://dx.doi.org/10.1007/s10489-019-01410-x
+ Xu, W., & Yi, Y., A robust replay detection algorithm for soccer video, IEEE Signal Processing Letters, 18(9), 509–512 (2011).  http://dx.doi.org/10.1109/lsp.2011.2161287
bibliography:summary.bib
